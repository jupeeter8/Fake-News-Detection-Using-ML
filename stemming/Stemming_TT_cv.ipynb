{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91913/2214948029.py:1: DtypeWarning: Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,213,214,215,216,217,218,219,220,221,222,223,224,226,227,228,229,231,232,233,234,236,237,238,239,240,241,243,244,245,246,247,248,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,280,281,282,283,284,285,286,287,288,290,291,292,294,295,296,297,299,300,301,302,303,304,305,306,307,309,310,311,312,313,314,315,316,318,319,320,322,323,324,326,327,328,330,331,332,333,335,336,337,338,339,340,341,342,343,344,345,346,348,349,350,351,353,354,355,356,358,359,360,361,363,364,365,366,368,369,370,371,373,374,375,376,378,379,380,381,383,384,385,386,388,389,390,391,393,394,395,396,397,398,399,400,401,403,404,405,406,407,409,410,411,412,414,415,416,417,419,420,421,422,424,425,426,427,429,430,431,432,434,435,436,437,439,440,441,442,444,445,446,447,448,450,451,452,453,455,456,457,458,459,460,462,463,464,465,467,468,469,470,471,472,473,474,475,477,478,479,480,482,483,484,485,487,488,489,490,492,493,494,495,497,498,499,500,501,503,504,505,506,508,509,510,511,512,514,515,516,517,519,520,521,522,524,525,526,527,529,530,531,532,534,535,536,537,539,540,541,543,544,545,546,547,548,549,550,551,552,553,554,556,557,558,559,561,562,566,567,568,569,570,571,572,574,575,576,577,578,579,581,582,583,585,586,587,588,589,590,592,593,594,595,596,597,598,599,601,602,603,604,605,607,608,609,610,612,613,614,615,617,618,619,621,622,623,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,675,676,677,678,679,680,681,683,684,685,686,687,689,697) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(r'./fake_or_real_news.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'../fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['author'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:, :3]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.label != 'REAL', 'label'] = 1\n",
    "data.loc[data.label == 'REAL', 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1:].values\n",
    "y = [i for sub in y for i in sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(c):\n",
    "    return c[\"title\"] + \" \" + c[\"text\"]\n",
    "x = data.apply(transform, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemm(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stop_words]\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        smell hillari fear daniel greenfield shillman ...\n",
       "1        watch exact moment paul ryan commit polit suic...\n",
       "2        kerri go pari gestur sympathi u secretari stat...\n",
       "3        berni support twitter erupt anger dnc tri warn...\n",
       "4        battl new york primari matter primari day new ...\n",
       "                               ...                        \n",
       "70795    tesla earn smash expect dramat chang report me...\n",
       "70796    rule ruler world realli work follow video must...\n",
       "70797    fact check trump right clinton might caus ww e...\n",
       "70798    caught tape isi destroy iraqi abram anti tank ...\n",
       "70799    obamacar architect admit law work design premi...\n",
       "Length: 64733, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.apply(stemm)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec = CountVectorizer(max_features=5000)\n",
    "tfidf_vec = TfidfVectorizer(max_features=5000)\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = c_vec.fit_transform(x_train).toarray()\n",
    "x_test = c_vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logReg(x, y):\n",
    "  lr_model.fit(x_train, y_train)\n",
    "  y_trainPred = lr_model.predict(x_train)\n",
    "  y_testPred = lr_model.predict(x_test)\n",
    "  print(\"Accuracy of training = \", accuracy_score(y_trainPred, y_train))\n",
    "  print('Training accuracy\\n')\n",
    "  print(classification_report(y_train, y_trainPred))\n",
    "  print(\"Accuracy of Testing = \", accuracy_score(y_testPred, y_test))\n",
    "  print('Testing Results\\n')\n",
    "  print(classification_report(y_test, y_testPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ani/Aiproj/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training =  0.9976248406905341\n",
      "Training accuracy\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      2519\n",
      "           1       1.00      1.00      1.00     49267\n",
      "\n",
      "    accuracy                           1.00     51786\n",
      "   macro avg       1.00      0.98      0.99     51786\n",
      "weighted avg       1.00      1.00      1.00     51786\n",
      "\n",
      "Accuracy of Testing =  0.9752066115702479\n",
      "Testing Results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       642\n",
      "           1       0.98      0.99      0.99     12305\n",
      "\n",
      "    accuracy                           0.98     12947\n",
      "   macro avg       0.89      0.83      0.86     12947\n",
      "weighted avg       0.97      0.98      0.97     12947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logReg(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbebb011c73bef65b9af370c38304bd776b34c20106fdce7fc239024997509d8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
